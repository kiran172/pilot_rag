{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/lib/python3.12/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: ollama in /opt/anaconda3/lib/python3.12/site-packages (0.4.5)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/anaconda3/lib/python3.12/site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from ollama) (2.9.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.11.0)\n",
      "Requirement already satisfied: tzdata in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2023.3)\n",
      "Requirement already satisfied: openpyxl in /opt/anaconda3/lib/python3.12/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /opt/anaconda3/lib/python3.12/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: langchain-community in /opt/anaconda3/lib/python3.12/site-packages (0.2.4)\n",
      "Requirement already satisfied: langchain-ollama in /opt/anaconda3/lib/python3.12/site-packages (0.2.2)\n",
      "Requirement already satisfied: langchain-groq in /opt/anaconda3/lib/python3.12/site-packages (0.2.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.2.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.2.43)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (2.32.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community) (8.2.2)\n",
      "INFO: pip is looking at multiple versions of langchain-ollama to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-ollama\n",
      "  Downloading langchain_ollama-0.2.3-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading langchain_ollama-0.2.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading langchain_ollama-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Downloading langchain_ollama-0.1.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-ollama) (0.4.5)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-groq) (0.13.1)\n",
      "INFO: pip is looking at multiple versions of langchain-groq to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-groq\n",
      "  Downloading langchain_groq-0.2.4-py3-none-any.whl.metadata (3.0 kB)\n",
      "  Downloading langchain_groq-0.2.3-py3-none-any.whl.metadata (3.0 kB)\n",
      "  Downloading langchain_groq-0.2.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading langchain_groq-0.2.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading langchain_groq-0.1.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from groq<1,>=0.4.1->langchain-groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from groq<1,>=0.4.1->langchain-groq) (2.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /opt/anaconda3/lib/python3.12/site-packages (from groq<1,>=0.4.1->langchain-groq) (4.11.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.23.2)\n",
      "Requirement already satisfied: tzdata in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2023.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading langchain_ollama-0.1.3-py3-none-any.whl (14 kB)\n",
      "Downloading langchain_groq-0.1.10-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: langchain-ollama, langchain-groq\n",
      "  Attempting uninstall: langchain-ollama\n",
      "    Found existing installation: langchain-ollama 0.2.2\n",
      "    Uninstalling langchain-ollama-0.2.2:\n",
      "      Successfully uninstalled langchain-ollama-0.2.2\n",
      "  Attempting uninstall: langchain-groq\n",
      "    Found existing installation: langchain-groq 0.2.2\n",
      "    Uninstalling langchain-groq-0.2.2:\n",
      "      Successfully uninstalled langchain-groq-0.2.2\n",
      "Successfully installed langchain-groq-0.1.10 langchain-ollama-0.1.3\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph) (0.2.43)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.16-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.53-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4,>=0.1->langgraph) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4,>=0.1->langgraph) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4,>=0.1->langgraph) (2.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4,>=0.1->langgraph) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4,>=0.1->langgraph) (4.11.0)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
      "  Using cached msgpack-1.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.27.2)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.7)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (2.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.1->langgraph) (2.32.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.1->langgraph) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.1->langgraph) (2.23.2)\n",
      "Requirement already satisfied: tzdata in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.1->langgraph) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.1->langgraph) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.1->langgraph) (2.2.2)\n",
      "Downloading langgraph-0.3.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langgraph_checkpoint-2.0.16-py3-none-any.whl (38 kB)\n",
      "Downloading langgraph_sdk-0.1.53-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached msgpack-1.1.0-cp312-cp312-macosx_11_0_arm64.whl (82 kB)\n",
      "Installing collected packages: msgpack, langgraph-sdk, langgraph-checkpoint, langgraph\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.3\n",
      "    Uninstalling msgpack-1.0.3:\n",
      "      Successfully uninstalled msgpack-1.0.3\n",
      "Successfully installed langgraph-0.3.0 langgraph-checkpoint-2.0.16 langgraph-sdk-0.1.53 msgpack-1.1.0\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "!pip install langchain\n",
    "!pip install faiss-cpu\n",
    "!pip install ollama\n",
    "!pip install openpyxl\n",
    "!pip install pandas\n",
    "!pip install requests\n",
    "!pip install langchain-community langchain-ollama langchain-groq\n",
    "!pip install langgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Constants\n",
    "KNOWLEDGE_BASE_DIR = r\"C:\\Users\\Akram\\OneDrive\\Documents\\kiran\\stenosis_txt\"\n",
    "JSON_FILE = \"final_raw_questions_stenosis.json\"\n",
    "#OUTPUT_FILE = \"responses.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 20:40:26,930 - INFO - Loading documents...\n",
      "2025-02-16 20:40:27,047 - INFO - Loaded 10 documents.\n"
     ]
    }
   ],
   "source": [
    "# Function to load text files from a directory\n",
    "def load_text_files(directory):\n",
    "    docs = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            loader = TextLoader(filepath, encoding=\"utf-8\")\n",
    "            docs.extend(loader.load())\n",
    "    return docs\n",
    "\n",
    "# Load documents\n",
    "logging.info(\"Loading documents...\")\n",
    "documents = load_text_files(KNOWLEDGE_BASE_DIR)\n",
    "logging.info(f\"Loaded {len(documents)} documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 20:40:54,974 - INFO - Splitting documents into chunks...\n",
      "2025-02-16 20:40:54,984 - INFO - Created 49 chunks.\n"
     ]
    }
   ],
   "source": [
    "# Function to split text into manageable chunks\n",
    "def split_text_into_chunks(docs, chunk_size=1000, chunk_overlap=200):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return text_splitter.split_documents(docs)\n",
    "\n",
    "# Split documents\n",
    "logging.info(\"Splitting documents into chunks...\")\n",
    "data_chunks = split_text_into_chunks(documents)\n",
    "logging.info(f\"Created {len(data_chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 20:42:27,980 - INFO - Creating vector store...\n",
      "C:\\Users\\Akram\\AppData\\Local\\Temp\\ipykernel_18332\\784870715.py:3: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")  # Adjust model if needed\n",
      "2025-02-16 20:44:28,593 - INFO - Loading faiss with AVX2 support.\n",
      "2025-02-16 20:44:28,762 - INFO - Successfully loaded faiss with AVX2 support.\n",
      "2025-02-16 20:44:28,778 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes.\n",
      "2025-02-16 20:44:28,791 - INFO - Vector store created.\n"
     ]
    }
   ],
   "source": [
    "# Initialize embedding model and create vector store\n",
    "logging.info(\"Creating vector store...\")\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")  # Adjust model if needed\n",
    "vectorstore = FAISS.from_documents(data_chunks, embedding_model)\n",
    "vectorstore.save_local(\"vectore_store\")\n",
    "logging.info(\"Vector store created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 20:47:03,759 - INFO - Retriever initialized.\n"
     ]
    }
   ],
   "source": [
    "# Initialize retriever\n",
    "vector_store=FAISS.load_local(\"vectore_store\",embedding_model,allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "logging.info(\"Retriever initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 22:58:39,284 - INFO - Loading questions...\n",
      "2025-02-16 22:58:39,289 - INFO - Loaded 2 questions.\n"
     ]
    }
   ],
   "source": [
    "def load_questions_from_json(json_file):\n",
    "    with open(json_file, \"r\") as file:\n",
    "        raw_questions = json.load(file)\n",
    "    \n",
    "    questions = []\n",
    "    for item in raw_questions:\n",
    "        question_text = item.get(\"question\", \"\").strip()\n",
    "        questions.append({\"question\": question_text})\n",
    "\n",
    "    return questions\n",
    "\n",
    "# Load questions\n",
    "logging.info(\"Loading questions...\")\n",
    "questions = load_questions_from_json(JSON_FILE)\n",
    "logging.info(f\"Loaded {len(questions)} questions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableParallel\n",
    "from langchain.tools import tool\n",
    "vector_store=FAISS.load_local(\"vectore_store\",embedding_model,allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "def combine_docs(docs):\n",
    "    combined = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    return combined \n",
    "\n",
    "\n",
    "class ResponseSchema(BaseModel):\n",
    "    option: Literal[\"opa\", \"opb\", \"opc\", \"opd\", \"unknown\"] = Field(\n",
    "\n",
    "        description=\"The selected answer option. Must be one of: 'opa', 'opb', 'opc', 'opd', or 'unknown'.\"\n",
    "    )\n",
    "\n",
    "\n",
    "@tool\n",
    "def retriver_tool(question:str):\n",
    "    \"\"\" Always use this tool to get medical information\"\"\"\n",
    "    try :\n",
    "        llm= ChatGroq(\n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "            api_key=\"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\"\n",
    "        ).with_structured_output(ResponseSchema)\n",
    "\n",
    "        # llm = ChatOllama(model=\"llama3.1\").with_structured_output(ResponseSchema)\n",
    "\n",
    "        context_docs=retriever.get_relevant_documents(question)\n",
    "        context=combine_docs(context_docs)\n",
    "        prompt = f\"\"\"\n",
    "        You are a medical AI assistant. Answer the following multiple-choice question based on the given context.\n",
    "\n",
    "        - If the context provides enough information, select the correct answer.\n",
    "        - If the context does NOT provide enough information, return \"unknown\".\n",
    "        - Your response should be only one of: \"opa\", \"opb\", \"opc\", \"opd\", or \"unknown\".\n",
    "        - Do not provide explanations or any extra text.\n",
    "\n",
    "        {question}  # Full question including options\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Your answer (choose only \"opa\", \"opb\", \"opc\", \"opd\", or \"unknown\"):\n",
    "        \"\"\"\n",
    "        prompt_template= PromptTemplate.from_template(prompt)\n",
    "        chain=(\n",
    "            RunnableParallel(context=retriever,question=RunnablePassthrough()) |\n",
    "            prompt_template |\n",
    "            llm\n",
    "        )\n",
    "\n",
    "        return chain.invoke(question)\n",
    "    except Exception as e:\n",
    "        return ResponseSchema(option=\"unknown\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 22:59:13,410 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opd\n"
     ]
    }
   ],
   "source": [
    "a=retriver_tool(\"Carotid artery stenosis screening invivo choice is - opa: USG, opb: CT, opc: MRI, opd: Doppler \")\n",
    "print(a.option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 22:56:27,029 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-16 22:56:32,661 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-16 22:56:32,777 - INFO - Saved results to responses.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_to_excel(questions, filename=\"responses.xlsx\"):\n",
    "    data = []\n",
    "    \n",
    "    for idx, question_data in enumerate(questions, start=1):\n",
    "\n",
    "        question = question_data.get(\"question\", \"No question provided\")\n",
    "        response = retriver_tool(question)\n",
    "        data.append({\n",
    "            \"Question\": question,  \n",
    "            \"Predicted Answer\": response.option  \n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel(filename, index=False)\n",
    "    logging.info(f\"Saved results to {filename}\")\n",
    "\n",
    "save_to_excel(questions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is Agent Keep it as backup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "from langchain_core.prompts.chat import MessagesPlaceholder,HumanMessagePromptTemplate\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.agents import create_tool_calling_agent,AgentExecutor\n",
    "\n",
    "\n",
    "llm= ChatGroq(\n",
    "            model=\"llama-3.1-8b-instant\",\n",
    "            api_key=\"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\"\n",
    "        )\n",
    "\n",
    "agent_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"\"\"You are a medical assistant designed to provide answers in the required output format.\n",
    "\n",
    "            - Always use the tool for answering medical-related questions.\n",
    "            - Your response should be only one of: \"opa\", \"opb\", \"opc\", \"opd\", or \"unknown\".\n",
    "            - Do not provide explanations or any extra text.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "medical_agent=create_tool_calling_agent(\n",
    "    llm,\n",
    "    tools=[retriver_tool],\n",
    "    prompt=agent_prompt\n",
    ")\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=medical_agent,\n",
    "    tools=[retriver_tool],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:44:15,198 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriver_tool` with `{'question': 'What is the best in vivo screening choice for carotid artery stenosis?'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:44:20,723 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3munknown\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:44:21,336 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriver_tool` with `{'question': 'Best in vivo screening choice for carotid artery stenosis is USG, CT, MRI or Doppler?'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:44:27,153 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mopd\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:44:27,768 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriver_tool` with `{'question': 'In vivo screening choices for carotid artery stenosis'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:44:33,088 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3munknown\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:44:33,720 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriver_tool` with `{'question': 'In vivo screening choices for carotid artery stenosis- USG, CT, MRI, Doppler'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:44:39,124 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3munknown\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:44:39,717 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriver_tool` with `{'question': ' What are the in vivo screening choices for carotid artery stenosis'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:44:45,280 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3munknown\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:44:46,072 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriver_tool` with `{'question': 'What are in vivo screening choices for carotid artery stenosis'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:44:52,250 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3munknown\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:44:52,866 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriver_tool` with `{'question': 'What is carotid artery stenosis in vivo screening?'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:44:58,139 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3munknown\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:44:58,772 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriver_tool` with `{'question': 'What are carotid artery stenosis screening in vivo choices?'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:45:04,632 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3munknown\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:45:05,268 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriver_tool` with `{'question': 'What are the in vivo screening choices for carotid artery stenosis?'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:45:10,417 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3munknown\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:45:11,252 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriver_tool` with `{'question': ' Carotid artery stenosis in vivo screening '}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:45:17,035 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3munknown\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:45:17,669 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriver_tool` with `{'question': ' Best carotid artery stenosis in vivo screening'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:45:22,901 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3munknown\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:45:23,555 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriver_tool` with `{'question': 'Carotid artery stenosis screening in vivo'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:45:28,824 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3munknown\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:45:29,468 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriver_tool` with `{'question': ' In vivo carotid artery stenosis screening'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:45:34,785 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3munknown\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:45:35,436 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriver_tool` with `{'question': ' Screening for carotid artery stenosis in vivo'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:45:41,468 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3munknown\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:45:42,080 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriver_tool` with `{'question': 'Carotid artery stenosis in vivo screening choices'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:45:47,325 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3munknown\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Carotid artery stenosis screening invivo choice is - opa: USG, opb: CT, opc: MRI, opd: Doppler', 'output': 'Agent stopped due to max iterations.'}\n"
     ]
    }
   ],
   "source": [
    "print(agent_executor.invoke({\"input\":\"Carotid artery stenosis screening invivo choice is - opa: USG, opb: CT, opc: MRI, opd: Doppler\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_llm_strict(question, context):\n",
    "    url = \"http://localhost:11434/api/chat\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a medical AI assistant. Answer the following multiple-choice question based on the given context.\n",
    "\n",
    "- If the context provides enough information, select the correct answer.\n",
    "- If the context does NOT provide enough information, return \"unknown\".\n",
    "- Your response should be only one of: \"opa\", \"opb\", \"opc\", \"opd\", or \"unknown\".\n",
    "- Do not provide explanations or any extra text.\n",
    "\n",
    "{question}  # Full question including options\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Your answer (choose only \"opa\", \"opb\", \"opc\", \"opd\", or \"unknown\"):\n",
    "\"\"\"\n",
    "    \n",
    "    data = {\n",
    "        \"model\": \"llama3.1:8b\",  # Adjust model as needed\n",
    "        \"temperature\": 0,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=data)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Process the response line by line to handle streaming JSON\n",
    "        raw_text = response.text.strip().split(\"\\n\")  # Split streamed JSON lines\n",
    "        final_response = \"\"\n",
    "\n",
    "        for line in raw_text:\n",
    "            try:\n",
    "                json_line = json.loads(line)  # Parse each line as JSON\n",
    "                if \"message\" in json_line and \"content\" in json_line[\"message\"]:\n",
    "                    final_response += json_line[\"message\"][\"content\"].strip().lower()\n",
    "            except json.JSONDecodeError:\n",
    "                continue  # Skip invalid JSON chunks\n",
    "\n",
    "        logging.info(f\"Final extracted response: {final_response}\")\n",
    "\n",
    "        valid_options = {\"opa\", \"opb\", \"opc\", \"opd\", \"unknown\"}\n",
    "\n",
    "        # Extract valid answer\n",
    "        if not final_response:\n",
    "            return \"unknown\"\n",
    "\n",
    "        processed_response = final_response.split()[0] if final_response.split() else \"unknown\"\n",
    "        \n",
    "        return processed_response if processed_response in valid_options else \"unknown\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error querying Ollama API: {e}\")\n",
    "        return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-groq in c:\\users\\akram\\anaconda3\\lib\\site-packages (0.2.4)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from langchain-groq) (0.18.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from langchain-groq) (0.3.35)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\akram\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (0.3.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (23.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\akram\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\akram\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain-groq) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (2.32.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\akram\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (2.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-12 01:55:33,261 - INFO - Final extracted response: opd\n",
      "2025-02-12 01:55:35,339 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:55:37,588 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:55:39,588 - INFO - Final extracted response: opd\n",
      "2025-02-12 01:55:42,070 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:55:43,956 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:55:46,210 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:55:48,311 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:55:50,313 - INFO - Final extracted response: opd\n",
      "2025-02-12 01:55:52,530 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:55:54,505 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:55:56,512 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:55:58,472 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:56:00,437 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:56:02,410 - INFO - Final extracted response: unknown\n",
      "2025-02-12 01:56:04,522 - INFO - Final extracted response: unknown\n",
      "2025-02-12 01:56:06,632 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:56:08,735 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:56:10,874 - INFO - Final extracted response: opd\n",
      "2025-02-12 01:56:12,840 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:56:14,805 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:56:16,777 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:56:18,879 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:56:21,327 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:56:23,299 - INFO - Final extracted response: unknown\n",
      "2025-02-12 01:56:25,632 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:56:27,604 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:56:29,446 - INFO - Final extracted response: unknown\n",
      "2025-02-12 01:56:31,651 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:56:33,498 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:56:35,592 - INFO - Final extracted response: opd\n",
      "2025-02-12 01:56:37,686 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:56:39,634 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:56:41,967 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:56:44,060 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:56:46,275 - INFO - Final extracted response: unknown\n",
      "2025-02-12 01:56:48,236 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:56:50,568 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:56:52,591 - INFO - Final extracted response: unknown\n",
      "2025-02-12 01:56:54,846 - INFO - Final extracted response: opd\n",
      "2025-02-12 01:56:56,680 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:56:59,141 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:57:01,355 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:57:03,325 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:57:05,291 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:57:07,285 - INFO - Final extracted response: opd\n",
      "2025-02-12 01:57:09,290 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:57:11,257 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:57:13,390 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:57:15,353 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:57:17,445 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:57:19,659 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:57:22,031 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:57:23,993 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:57:25,960 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:57:28,093 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:57:30,179 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:57:32,426 - INFO - Final extracted response: opd\n",
      "2025-02-12 01:57:34,381 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:57:36,345 - INFO - Final extracted response: unknown\n",
      "2025-02-12 01:57:38,444 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:57:40,385 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:57:42,482 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:57:44,879 - INFO - Final extracted response: opd.\n",
      "2025-02-12 01:57:47,020 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:57:49,281 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:57:51,246 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:57:53,254 - INFO - Final extracted response: opd\n",
      "2025-02-12 01:57:55,463 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:57:57,544 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:57:59,511 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:58:01,462 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:58:03,556 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:58:05,652 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:58:07,621 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:58:09,571 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:58:11,542 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:58:13,885 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:58:16,229 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:58:18,190 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:58:20,023 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:58:22,356 - INFO - Final extracted response: unknown\n",
      "2025-02-12 01:58:24,505 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:58:26,508 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:58:28,757 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:58:30,792 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:58:32,924 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:58:35,053 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:58:37,129 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:58:39,078 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:58:41,037 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:58:43,045 - INFO - Final extracted response: unknown.\n",
      "2025-02-12 01:58:45,240 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:58:47,378 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:58:49,515 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:58:51,775 - INFO - Final extracted response: opd\n",
      "2025-02-12 01:58:53,989 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:58:55,958 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:58:58,121 - INFO - Final extracted response: opd\n",
      "2025-02-12 01:59:00,325 - INFO - Final extracted response: unknown\n",
      "2025-02-12 01:59:02,424 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:59:04,393 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:59:06,605 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:59:08,847 - INFO - Final extracted response: opd\n",
      "2025-02-12 01:59:10,982 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:59:12,942 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:59:15,148 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:59:17,106 - INFO - Final extracted response: opc\n",
      "2025-02-12 01:59:19,103 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:59:21,053 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:59:23,181 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:59:25,363 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:59:27,323 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:59:29,448 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:59:31,434 - INFO - Final extracted response: opd\n",
      "2025-02-12 01:59:33,530 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:59:35,660 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:59:37,712 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:59:39,710 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:59:41,960 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:59:44,166 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:59:46,411 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:59:48,734 - INFO - Final extracted response: unknown\n",
      "2025-02-12 01:59:50,946 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:59:52,940 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:59:55,071 - INFO - Final extracted response: opb\n",
      "2025-02-12 01:59:57,391 - INFO - Final extracted response: opa\n",
      "2025-02-12 01:59:59,418 - INFO - Final extracted response: opd.\n",
      "2025-02-12 02:00:01,633 - INFO - Final extracted response: opc\n",
      "2025-02-12 02:00:03,841 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:00:05,831 - INFO - Final extracted response: opd\n",
      "2025-02-12 02:00:07,832 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:00:09,858 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:00:11,851 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:00:14,209 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:00:16,040 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:00:18,284 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:00:20,274 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:00:22,420 - INFO - Final extracted response: unknown\n",
      "2025-02-12 02:00:24,387 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:00:26,484 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:00:28,573 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:00:30,782 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:00:33,231 - INFO - Final extracted response: unknown\n",
      "2025-02-12 02:00:35,317 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:00:37,271 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:00:39,479 - INFO - Final extracted response: unknown\n",
      "2025-02-12 02:00:41,681 - INFO - Final extracted response: opc\n",
      "2025-02-12 02:00:43,814 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:00:46,125 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:00:48,698 - INFO - Final extracted response: opd\n",
      "2025-02-12 02:00:50,950 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:00:52,907 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:00:54,861 - INFO - Final extracted response: opc\n",
      "2025-02-12 02:00:56,859 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:00:58,810 - INFO - Final extracted response: unknown\n",
      "2025-02-12 02:01:00,902 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:01:02,738 - INFO - Final extracted response: unknown\n",
      "2025-02-12 02:01:04,696 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:01:06,785 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:01:09,037 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:01:10,995 - INFO - Final extracted response: opc\n",
      "2025-02-12 02:01:13,127 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:01:15,262 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:01:17,249 - INFO - Final extracted response: opd\n",
      "2025-02-12 02:01:19,378 - INFO - Final extracted response: opd\n",
      "2025-02-12 02:01:21,584 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:01:23,538 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:01:25,850 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:01:27,819 - INFO - Final extracted response: unknown\n",
      "2025-02-12 02:01:29,914 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:01:32,007 - INFO - Final extracted response: opc\n",
      "2025-02-12 02:01:33,999 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:01:36,244 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:01:38,558 - INFO - Final extracted response: opc\n",
      "2025-02-12 02:01:40,550 - INFO - Final extracted response: opd\n",
      "2025-02-12 02:01:42,754 - INFO - Final extracted response: radiculopathy\n",
      "2025-02-12 02:01:44,592 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:01:46,721 - INFO - Final extracted response: opd\n",
      "2025-02-12 02:01:48,713 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:01:50,666 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:01:52,980 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:01:54,975 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:01:56,929 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:01:58,887 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:02:00,848 - INFO - Final extracted response: opc\n",
      "2025-02-12 02:02:03,181 - INFO - Final extracted response: opd:intravenousopioids\n",
      "2025-02-12 02:02:05,498 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:02:07,497 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:02:09,742 - INFO - Final extracted response: opd:failedcircumcision\n",
      "2025-02-12 02:02:11,693 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:02:13,822 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:02:16,132 - INFO - Final extracted response: unknown\n",
      "2025-02-12 02:02:18,448 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:02:20,658 - INFO - Final extracted response: unknown\n",
      "2025-02-12 02:02:22,912 - INFO - Final extracted response: opd\n",
      "2025-02-12 02:02:25,123 - INFO - Final extracted response: unknown\n",
      "2025-02-12 02:02:27,270 - INFO - Final extracted response: unknown\n",
      "2025-02-12 02:02:29,627 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:02:31,456 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:02:33,586 - INFO - Final extracted response: opd\n",
      "2025-02-12 02:02:35,899 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:02:38,022 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:02:40,015 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:02:41,974 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:02:44,021 - INFO - Final extracted response: opd\n",
      "2025-02-12 02:02:46,016 - INFO - Final extracted response: opd\n",
      "2025-02-12 02:02:48,011 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:02:50,327 - INFO - Final extracted response: unknown\n",
      "2025-02-12 02:02:52,578 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:02:54,786 - INFO - Final extracted response: unknown\n",
      "2025-02-12 02:02:56,744 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:02:58,880 - INFO - Final extracted response: opc\n",
      "2025-02-12 02:03:01,312 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:03:03,994 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:03:05,995 - INFO - Final extracted response: opd\n",
      "2025-02-12 02:03:07,988 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:03:09,946 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:03:11,994 - INFO - Final extracted response: opd\n",
      "2025-02-12 02:03:13,950 - INFO - Final extracted response: unknown\n",
      "2025-02-12 02:03:16,109 - INFO - Final extracted response: opd:duringfeeding\n",
      "2025-02-12 02:03:18,069 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:03:20,201 - INFO - Final extracted response: opd\n",
      "2025-02-12 02:03:22,158 - INFO - Final extracted response: opc\n",
      "2025-02-12 02:03:24,301 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:03:26,435 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:03:28,489 - INFO - Final extracted response: opc\n",
      "2025-02-12 02:03:30,731 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:03:32,933 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:03:34,925 - INFO - Final extracted response: unknown\n",
      "2025-02-12 02:03:36,883 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:03:39,010 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:03:40,968 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:03:42,965 - INFO - Final extracted response: opd\n",
      "2025-02-12 02:03:45,104 - INFO - Final extracted response: opd\n",
      "2025-02-12 02:03:47,193 - INFO - Final extracted response: opc\n",
      "2025-02-12 02:03:49,285 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:03:51,597 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:03:53,539 - INFO - Final extracted response: opc\n",
      "2025-02-12 02:03:55,789 - INFO - Final extracted response: opb\n",
      "2025-02-12 02:03:57,882 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:03:59,933 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:04:02,036 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:04:03,994 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:04:05,951 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:04:08,042 - INFO - Final extracted response: opa\n",
      "2025-02-12 02:04:10,250 - INFO - Final extracted response: unknown\n",
      "2025-02-12 02:04:10,738 - INFO - Saved results to responses.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_to_excel(questions, filename=\"responses.xlsx\"):\n",
    "    data = []\n",
    "    \n",
    "    for idx, question_data in enumerate(questions, start=1):\n",
    "        question = question_data.get(\"question\", \"No question provided\")\n",
    "\n",
    "        # Retrieve relevant context\n",
    "        retrieved_docs = retriever.get_relevant_documents(question)\n",
    "        context = combine_docs(retrieved_docs)\n",
    "        \n",
    "        # Query LLM for the answer (we no longer pass options separately)\n",
    "        response = ollama_llm_strict(question, context)\n",
    "\n",
    "        # Append data for Excel\n",
    "        data.append({\n",
    "            \"Question\": question,  \n",
    "            \"Predicted Answer\": response  # Only store the predicted answer\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Save to Excel\n",
    "    df.to_excel(filename, index=False)\n",
    "    logging.info(f\"Saved results to {filename}\")\n",
    "\n",
    "# Run function to save results\n",
    "save_to_excel(questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
